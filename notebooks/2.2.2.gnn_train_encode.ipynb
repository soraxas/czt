{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d892b5e-2f3b-4182-bedb-d332bfc3a353",
   "metadata": {},
   "source": [
    "# GNN Training and Encoding\n",
    "\n",
    "* Train a GNN based on enriched features in an unsupervised fashion, and use the resulting model to encode the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8498bf1-d368-4d15-a5bf-559eb6e3918b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9d04f0-a64d-457b-aacf-1a3737e07e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_input_dir = \"processed_data\"\n",
    "site_name = \"HCBHSGSG_Bank_9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d84f89f-fe0a-4387-92a2-49ca9143c141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_names = [\"train\", \"test\"]\n",
    "df_feats = {}\n",
    "df_edges = {}\n",
    "for ds_name in dataset_names:\n",
    "    # Get feature and class\n",
    "    file_name = os.path.join(site_input_dir, site_name, f\"{ds_name}_normalized.csv\")\n",
    "    df = pd.read_csv(file_name, index_col=0)\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"Currency_Country\",\n",
    "            \"Beneficiary_BIC\",\n",
    "            \"Currency\",\n",
    "            \"Receiver_BIC\",\n",
    "            \"Sender_BIC\",\n",
    "        ]\n",
    "    )\n",
    "    df_feats[ds_name] = df\n",
    "    # Get edge map\n",
    "    file_name = os.path.join(site_input_dir, site_name, f\"{ds_name}_edgemap.csv\")\n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "    # Add column names to the edge map\n",
    "    df.columns = [\"UETR_1\", \"UETR_2\"]\n",
    "    df_edges[ds_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b6b9d-7046-4ed4-8a7e-ce1f74ddf694",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepared Data for Unsupervised GNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd5be54-c5e7-43c7-ad4f-de29a09bc7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "node_ids = {}\n",
    "node_features = {}\n",
    "edge_indices = {}\n",
    "weights = {}\n",
    "labels = {}\n",
    "\n",
    "for ds_name in dataset_names:\n",
    "    df_feat_class = df_feats[ds_name]\n",
    "    df_edge = df_edges[ds_name]\n",
    "\n",
    "    # Sort the data by UETR\n",
    "    df_feat_class = df_feat_class.sort_values(by=\"Transaction_ID\").reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    # Generate UETR-index map with the feature list\n",
    "    node_id = df_feat_class[\"Transaction_ID\"].values\n",
    "    map_id = {j: i for i, j in enumerate(node_id)}  # mapping nodes to indexes\n",
    "    node_ids[ds_name] = node_id\n",
    "\n",
    "    # Get class labels\n",
    "    labels[ds_name] = df_feat_class[\"Fraud_Label\"].values\n",
    "\n",
    "    # Map UETR to indexes in the edge map\n",
    "    edges = df_edge.copy()\n",
    "    edges.UETR_1 = edges.UETR_1.map(map_id)\n",
    "    edges.UETR_2 = edges.UETR_2.map(map_id)\n",
    "    edges = edges.astype(int)\n",
    "\n",
    "    # for undirected graph\n",
    "    edge_index = np.array(edges.values).T\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "    edge_indices[ds_name] = edge_index\n",
    "    weights[ds_name] = torch.tensor([1] * edge_index.shape[1], dtype=torch.float)\n",
    "\n",
    "    # UETR mapped to corresponding indexes, drop UETR and class\n",
    "    node_feature = df_feat_class.drop([\"Transaction_ID\", \"Fraud_Label\"], axis=1).copy()\n",
    "    node_feature = torch.tensor(np.array(node_feature.values), dtype=torch.float)\n",
    "    node_features[ds_name] = node_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b192a7-05be-4591-b937-7bab878277ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unsupervised GNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f326a613-e683-4f67-810d-aece3d90349e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.8859\n",
      "Epoch: 02, Loss: 0.8394\n",
      "Epoch: 03, Loss: 0.8093\n",
      "Epoch: 04, Loss: 0.7704\n",
      "Epoch: 05, Loss: 0.7573\n",
      "Epoch: 06, Loss: 0.7322\n",
      "Epoch: 07, Loss: 0.7152\n",
      "Epoch: 08, Loss: 0.7016\n",
      "Epoch: 09, Loss: 0.6863\n",
      "Epoch: 10, Loss: 0.6735\n",
      "Epoch: 11, Loss: 0.6598\n",
      "Epoch: 12, Loss: 0.6509\n",
      "Epoch: 13, Loss: 0.6446\n",
      "Epoch: 14, Loss: 0.6461\n",
      "Epoch: 15, Loss: 0.6378\n",
      "Epoch: 16, Loss: 0.6130\n",
      "Epoch: 17, Loss: 0.6196\n",
      "Epoch: 18, Loss: 0.6024\n",
      "Epoch: 19, Loss: 0.6176\n",
      "Epoch: 20, Loss: 0.6044\n",
      "Epoch: 21, Loss: 0.5929\n",
      "Epoch: 22, Loss: 0.5969\n",
      "Epoch: 23, Loss: 0.5806\n",
      "Epoch: 24, Loss: 0.5899\n",
      "Epoch: 25, Loss: 0.5810\n",
      "Epoch: 26, Loss: 0.5851\n",
      "Epoch: 27, Loss: 0.5784\n",
      "Epoch: 28, Loss: 0.5713\n",
      "Epoch: 29, Loss: 0.5690\n",
      "Epoch: 30, Loss: 0.5515\n",
      "Epoch: 31, Loss: 0.5616\n",
      "Epoch: 32, Loss: 0.5537\n",
      "Epoch: 33, Loss: 0.5436\n",
      "Epoch: 34, Loss: 0.5464\n",
      "Epoch: 35, Loss: 0.5499\n",
      "Epoch: 36, Loss: 0.5505\n",
      "Epoch: 37, Loss: 0.5258\n",
      "Epoch: 38, Loss: 0.5378\n",
      "Epoch: 39, Loss: 0.5466\n",
      "Epoch: 40, Loss: 0.5467\n",
      "Epoch: 41, Loss: 0.5337\n",
      "Epoch: 42, Loss: 0.5215\n",
      "Epoch: 43, Loss: 0.5199\n",
      "Epoch: 44, Loss: 0.5198\n",
      "Epoch: 45, Loss: 0.5169\n",
      "Epoch: 46, Loss: 0.5209\n",
      "Epoch: 47, Loss: 0.5085\n",
      "Epoch: 48, Loss: 0.5219\n",
      "Epoch: 49, Loss: 0.5178\n",
      "Epoch: 50, Loss: 0.5035\n",
      "Epoch: 51, Loss: 0.5050\n",
      "Epoch: 52, Loss: 0.5077\n",
      "Epoch: 53, Loss: 0.5141\n",
      "Epoch: 54, Loss: 0.5109\n",
      "Epoch: 55, Loss: 0.5106\n",
      "Epoch: 56, Loss: 0.5009\n",
      "Epoch: 57, Loss: 0.4931\n",
      "Epoch: 58, Loss: 0.4760\n",
      "Epoch: 59, Loss: 0.4892\n",
      "Epoch: 60, Loss: 0.4933\n",
      "Epoch: 61, Loss: 0.5165\n",
      "Epoch: 62, Loss: 0.4834\n",
      "Epoch: 63, Loss: 0.4941\n",
      "Epoch: 64, Loss: 0.4678\n",
      "Epoch: 65, Loss: 0.4882\n",
      "Epoch: 66, Loss: 0.4754\n",
      "Epoch: 67, Loss: 0.4758\n",
      "Epoch: 68, Loss: 0.4842\n",
      "Epoch: 69, Loss: 0.4903\n",
      "Epoch: 70, Loss: 0.4738\n",
      "Epoch: 71, Loss: 0.4598\n",
      "Epoch: 72, Loss: 0.4930\n",
      "Epoch: 73, Loss: 0.4909\n",
      "Epoch: 74, Loss: 0.4927\n",
      "Epoch: 75, Loss: 0.4694\n",
      "Epoch: 76, Loss: 0.4750\n",
      "Epoch: 77, Loss: 0.4816\n",
      "Epoch: 78, Loss: 0.4791\n",
      "Epoch: 79, Loss: 0.4534\n",
      "Epoch: 80, Loss: 0.4741\n",
      "Epoch: 81, Loss: 0.4595\n",
      "Epoch: 82, Loss: 0.4852\n",
      "Epoch: 83, Loss: 0.4856\n",
      "Epoch: 84, Loss: 0.4731\n",
      "Epoch: 85, Loss: 0.4679\n",
      "Epoch: 86, Loss: 0.4635\n",
      "Epoch: 87, Loss: 0.4651\n",
      "Epoch: 88, Loss: 0.4414\n",
      "Epoch: 89, Loss: 0.4608\n",
      "Epoch: 90, Loss: 0.4451\n",
      "Epoch: 91, Loss: 0.4548\n",
      "Epoch: 92, Loss: 0.4544\n",
      "Epoch: 93, Loss: 0.4668\n",
      "Epoch: 94, Loss: 0.4660\n",
      "Epoch: 95, Loss: 0.4596\n",
      "Epoch: 96, Loss: 0.4686\n",
      "Epoch: 97, Loss: 0.4621\n",
      "Epoch: 98, Loss: 0.4542\n",
      "Epoch: 99, Loss: 0.4507\n",
      "Epoch: 100, Loss: 0.4724\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "\n",
    "output_dir = os.path.join(site_input_dir, site_name)\n",
    "DEVICE = \"cuda:0\"\n",
    "writer = SummaryWriter(output_dir)\n",
    "epochs = 100\n",
    "\n",
    "# Converting data to PyG graph data format\n",
    "train_data = Data(\n",
    "    x=node_features[\"train\"],\n",
    "    edge_index=edge_indices[\"train\"],\n",
    "    edge_attr=weights[\"train\"],\n",
    ")\n",
    "\n",
    "# Define the dataloader for graphsage training\n",
    "loader = LinkNeighborLoader(\n",
    "    train_data,\n",
    "    batch_size=2048,\n",
    "    shuffle=True,\n",
    "    neg_sampling_ratio=1.0,\n",
    "    num_neighbors=[10, 10],\n",
    "    num_workers=6,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = GraphSAGE(\n",
    "    in_channels=node_features[\"train\"].shape[1],\n",
    "    hidden_channels=64,\n",
    "    num_layers=2,\n",
    "    out_channels=64,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.to(DEVICE)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = instance_count = 0\n",
    "\n",
    "    for data in loader:\n",
    "        # get the inputs data\n",
    "        data = data.to(DEVICE)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        h = model(data.x, data.edge_index)\n",
    "        h_src = h[data.edge_label_index[0]]\n",
    "        h_dst = h[data.edge_label_index[1]]\n",
    "        link_pred = (h_src * h_dst).sum(dim=-1)  # Inner product.\n",
    "        loss = F.binary_cross_entropy_with_logits(link_pred, data.edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # add record\n",
    "        running_loss += float(loss.item()) * link_pred.numel()\n",
    "        instance_count += link_pred.numel()\n",
    "    print(f\"Epoch: {epoch:02d}, Loss: {running_loss / instance_count:.4f}\")\n",
    "    writer.add_scalar(\"train_loss\", running_loss / instance_count, epoch)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5b581-1688-4c43-a83a-f3b152d05729",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GNN Inference - Encoding the Raw Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dfe6156-1049-41c5-82d5-b81fa1814160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model and perform inference / encoding\n",
    "model_enc = GraphSAGE(\n",
    "    in_channels=node_features[\"train\"].shape[1],\n",
    "    hidden_channels=64,\n",
    "    num_layers=2,\n",
    "    out_channels=64,\n",
    ")\n",
    "model_enc.load_state_dict(torch.load(os.path.join(output_dir, \"model.pt\")))\n",
    "model_enc.eval()\n",
    "\n",
    "embeds = {}\n",
    "# Perform encoding\n",
    "for ds_name in dataset_names:\n",
    "    h = model_enc(node_features[ds_name], edge_indices[ds_name])\n",
    "    embed = pd.DataFrame(h.cpu().detach().numpy())\n",
    "    # Add column names as V_0, V_1, ... V_63\n",
    "    embed.columns = [f\"V_{i}\" for i in range(embed.shape[1])]\n",
    "    # Concatenate the node ids and class labels with the encoded features\n",
    "    embed[\"Transaction_ID\"] = node_ids[ds_name]\n",
    "    embed[\"Fraud_Label\"] = labels[ds_name]\n",
    "    # Move the UETR and Class columns to the front\n",
    "    embed = embed[\n",
    "        [\"Transaction_ID\", \"Fraud_Label\"]\n",
    "        + [col for col in embed.columns if col not in [\"Transaction_ID\", \"Fraud_Label\"]]\n",
    "    ]\n",
    "    embed.to_csv(os.path.join(output_dir, f\"{ds_name}_embedding.csv\"), index=False)\n",
    "    embeds[ds_name] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1b8925c-6890-4a45-a9c4-f80399b463cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘/tmp/dataset/horizontal_credit_fraud_data/ZHSZUS33_Bank_1’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! find /tmp/dataset/horizontal_credit_fraud_data/ZHSZUS33_Bank_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5adcd468-edaf-4759-ac2d-09902811c97a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Fraud_Label</th>\n",
       "      <th>V_0</th>\n",
       "      <th>V_1</th>\n",
       "      <th>V_2</th>\n",
       "      <th>V_3</th>\n",
       "      <th>V_4</th>\n",
       "      <th>V_5</th>\n",
       "      <th>V_6</th>\n",
       "      <th>V_7</th>\n",
       "      <th>...</th>\n",
       "      <th>V_54</th>\n",
       "      <th>V_55</th>\n",
       "      <th>V_56</th>\n",
       "      <th>V_57</th>\n",
       "      <th>V_58</th>\n",
       "      <th>V_59</th>\n",
       "      <th>V_60</th>\n",
       "      <th>V_61</th>\n",
       "      <th>V_62</th>\n",
       "      <th>V_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028973</td>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>-0.011008</td>\n",
       "      <td>-0.065842</td>\n",
       "      <td>-0.024214</td>\n",
       "      <td>0.073006</td>\n",
       "      <td>0.140930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148318</td>\n",
       "      <td>-0.164059</td>\n",
       "      <td>0.088292</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>0.109578</td>\n",
       "      <td>-0.013932</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>-0.012820</td>\n",
       "      <td>-0.050226</td>\n",
       "      <td>0.067718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172293</td>\n",
       "      <td>0.218145</td>\n",
       "      <td>0.120312</td>\n",
       "      <td>0.113256</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>0.061711</td>\n",
       "      <td>-0.140634</td>\n",
       "      <td>0.029781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051324</td>\n",
       "      <td>-0.066613</td>\n",
       "      <td>-0.078133</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.058151</td>\n",
       "      <td>-0.202513</td>\n",
       "      <td>0.125230</td>\n",
       "      <td>0.080344</td>\n",
       "      <td>-0.114718</td>\n",
       "      <td>-0.106416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_10022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.056977</td>\n",
       "      <td>0.017150</td>\n",
       "      <td>-0.160322</td>\n",
       "      <td>0.013378</td>\n",
       "      <td>-0.102321</td>\n",
       "      <td>0.040907</td>\n",
       "      <td>-0.089257</td>\n",
       "      <td>0.049358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>-0.004594</td>\n",
       "      <td>0.050215</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>-0.050697</td>\n",
       "      <td>-0.083995</td>\n",
       "      <td>-0.025159</td>\n",
       "      <td>0.032874</td>\n",
       "      <td>-0.084087</td>\n",
       "      <td>-0.010891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_10027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071584</td>\n",
       "      <td>0.148986</td>\n",
       "      <td>0.015382</td>\n",
       "      <td>0.058536</td>\n",
       "      <td>-0.016526</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.053840</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051510</td>\n",
       "      <td>-0.128119</td>\n",
       "      <td>0.043044</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.078473</td>\n",
       "      <td>-0.125906</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>-0.104389</td>\n",
       "      <td>-0.016299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_10037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088335</td>\n",
       "      <td>0.076789</td>\n",
       "      <td>0.092709</td>\n",
       "      <td>-0.042632</td>\n",
       "      <td>-0.015114</td>\n",
       "      <td>-0.073617</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.121103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143355</td>\n",
       "      <td>-0.201269</td>\n",
       "      <td>0.098042</td>\n",
       "      <td>-0.018394</td>\n",
       "      <td>0.132004</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.039008</td>\n",
       "      <td>0.062403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>TXN_9960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.081266</td>\n",
       "      <td>-0.110061</td>\n",
       "      <td>-0.198649</td>\n",
       "      <td>-0.092774</td>\n",
       "      <td>-0.231194</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.090064</td>\n",
       "      <td>0.100205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081326</td>\n",
       "      <td>-0.006626</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>-0.035140</td>\n",
       "      <td>0.102030</td>\n",
       "      <td>-0.125337</td>\n",
       "      <td>-0.050900</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.112276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>TXN_9973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112650</td>\n",
       "      <td>-0.041571</td>\n",
       "      <td>-0.183561</td>\n",
       "      <td>0.030091</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>-0.172339</td>\n",
       "      <td>-0.059009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.065834</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>-0.103677</td>\n",
       "      <td>-0.138047</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>-0.074434</td>\n",
       "      <td>-0.104596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>TXN_9974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>-0.093850</td>\n",
       "      <td>-0.252976</td>\n",
       "      <td>-0.048655</td>\n",
       "      <td>-0.151257</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>-0.125361</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087925</td>\n",
       "      <td>0.035664</td>\n",
       "      <td>0.059005</td>\n",
       "      <td>-0.025692</td>\n",
       "      <td>-0.121029</td>\n",
       "      <td>-0.041755</td>\n",
       "      <td>-0.081888</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.018904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>TXN_9977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.020019</td>\n",
       "      <td>0.088668</td>\n",
       "      <td>0.056534</td>\n",
       "      <td>-0.000961</td>\n",
       "      <td>-0.134506</td>\n",
       "      <td>-0.014854</td>\n",
       "      <td>0.146039</td>\n",
       "      <td>0.166312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201459</td>\n",
       "      <td>-0.158649</td>\n",
       "      <td>0.093627</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.099505</td>\n",
       "      <td>0.031917</td>\n",
       "      <td>0.034907</td>\n",
       "      <td>-0.094791</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.115109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>TXN_9992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095686</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.382008</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>0.312642</td>\n",
       "      <td>-0.088948</td>\n",
       "      <td>0.061459</td>\n",
       "      <td>-0.190049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082809</td>\n",
       "      <td>0.114837</td>\n",
       "      <td>-0.200143</td>\n",
       "      <td>-0.018875</td>\n",
       "      <td>0.098501</td>\n",
       "      <td>0.186308</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>-0.013033</td>\n",
       "      <td>0.188398</td>\n",
       "      <td>-0.071046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3601 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transaction_ID  Fraud_Label       V_0       V_1       V_2       V_3  \\\n",
       "0             TXN_1          0.0 -0.028973  0.095657  0.042164 -0.011008   \n",
       "1           TXN_100          0.0  0.172293  0.218145  0.120312  0.113256   \n",
       "2         TXN_10022          1.0  0.056977  0.017150 -0.160322  0.013378   \n",
       "3         TXN_10027          1.0  0.071584  0.148986  0.015382  0.058536   \n",
       "4         TXN_10037          0.0 -0.088335  0.076789  0.092709 -0.042632   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "3596       TXN_9960          0.0 -0.081266 -0.110061 -0.198649 -0.092774   \n",
       "3597       TXN_9973          0.0  0.112650 -0.041571 -0.183561  0.030091   \n",
       "3598       TXN_9974          1.0  0.006942 -0.093850 -0.252976 -0.048655   \n",
       "3599       TXN_9977          0.0 -0.020019  0.088668  0.056534 -0.000961   \n",
       "3600       TXN_9992          0.0 -0.095686 -0.001444  0.382008  0.018354   \n",
       "\n",
       "           V_4       V_5       V_6       V_7  ...      V_54      V_55  \\\n",
       "0    -0.065842 -0.024214  0.073006  0.140930  ... -0.148318 -0.164059   \n",
       "1     0.063575  0.061711 -0.140634  0.029781  ...  0.051324 -0.066613   \n",
       "2    -0.102321  0.040907 -0.089257  0.049358  ...  0.023719 -0.004594   \n",
       "3    -0.016526  0.004357 -0.053840  0.091114  ... -0.051510 -0.128119   \n",
       "4    -0.015114 -0.073617  0.066298  0.121103  ... -0.143355 -0.201269   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "3596 -0.231194  0.002604  0.090064  0.100205  ... -0.081326 -0.006626   \n",
       "3597  0.007039  0.064889 -0.172339 -0.059009  ...  0.127273  0.065834   \n",
       "3598 -0.151257  0.024363 -0.125361  0.012513  ...  0.087925  0.035664   \n",
       "3599 -0.134506 -0.014854  0.146039  0.166312  ... -0.201459 -0.158649   \n",
       "3600  0.312642 -0.088948  0.061459 -0.190049  ...  0.082809  0.114837   \n",
       "\n",
       "          V_56      V_57      V_58      V_59      V_60      V_61      V_62  \\\n",
       "0     0.088292  0.007325  0.109578 -0.013932  0.011894 -0.012820 -0.050226   \n",
       "1    -0.078133  0.026027  0.058151 -0.202513  0.125230  0.080344 -0.114718   \n",
       "2     0.050215  0.016388 -0.050697 -0.083995 -0.025159  0.032874 -0.084087   \n",
       "3     0.043044  0.021109  0.078473 -0.125906  0.064768  0.029336 -0.104389   \n",
       "4     0.098042 -0.018394  0.132004  0.011132  0.019389  0.014127 -0.039008   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3596  0.115972  0.003366 -0.035140  0.102030 -0.125337 -0.050900  0.006397   \n",
       "3597 -0.000823  0.029885 -0.103677 -0.138047 -0.001729  0.083217 -0.074434   \n",
       "3598  0.059005 -0.025692 -0.121029 -0.041755 -0.081888  0.028827 -0.066285   \n",
       "3599  0.093627 -0.001041  0.099505  0.031917  0.034907 -0.094791 -0.001101   \n",
       "3600 -0.200143 -0.018875  0.098501  0.186308  0.058104 -0.013033  0.188398   \n",
       "\n",
       "          V_63  \n",
       "0     0.067718  \n",
       "1    -0.106416  \n",
       "2    -0.010891  \n",
       "3    -0.016299  \n",
       "4     0.062403  \n",
       "...        ...  \n",
       "3596  0.112276  \n",
       "3597 -0.104596  \n",
       "3598 -0.018904  \n",
       "3599  0.115109  \n",
       "3600 -0.071046  \n",
       "\n",
       "[3601 rows x 66 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591e4e1-74b1-465c-8124-eaf9829a6a8e",
   "metadata": {},
   "source": [
    "Let's go back to the [XGBoost Notebook](../xgboost.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926970e-a4e9-41a7-a166-0d11f8e9e320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
